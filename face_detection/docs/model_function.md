# 8. 模型功能和作用

本文档介绍人脸识别模块使用的两个核心模型：RetinaFace 和 MobileFaceNet 的功能、作用及技术特性。

---

## 8.1 模型架构总览

人脸识别流程使用两阶段模型：

```
输入图像
    ↓
[模型1] RetinaFace
    ↓
人脸框 + 5个关键点
    ↓
[人脸对齐]
    ↓
[模型2] MobileFaceNet
    ↓
512维特征向量
```

---

## 8.2 RetinaFace 模型

### 8.2.1 功能定位

**RetinaFace** 是一个**人脸检测模型**，负责在图像中定位人脸位置并输出关键点。

**核心功能**：
- 检测图像中的人脸位置（边界框）
- 输出每个人脸的 5 个关键点（双眼、鼻尖、嘴角）
- 支持多人脸检测（最多 128 个）
- 提供置信度分数用于过滤低质量检测

### 8.2.2 模型规格

| 属性 | 值 |
|------|---|
| **模型架构** | RetinaNet + FPN |
| **输入尺寸** | 640×640×3 (RGB) |
| **输入格式** | 浮点数组，范围 [-1, 1] |
| **输出节点** | 3 个（多尺度检测） |
| **检测范围** | 40×40 ~ 640×640 像素 |
| **模型文件** | `RetinaFace.rknn` (~2.5MB) |

### 8.2.3 输出格式

每个检测框包含 **15 个值**：

| 索引 | 含义 |
|------|------|
| 0~3 | 边界框坐标 (x, y, w, h) |
| 4~5 | 左眼中心 (x, y) |
| 6~7 | 右眼中心 (x, y) |
| 8~9 | 鼻尖 (x, y) |
| 10~11 | 左嘴角 (x, y) |
| 12~13 | 右嘴角 (x, y) |
| 14 | 置信度分数 [0, 1] |

**关键点顺序**（遵循行业标准）：
```
      左眼(0) ● ● 右眼(1)
              ●
           鼻尖(2)

    左嘴角(3) ● ● 右嘴角(4)
```

### 8.2.4 技术特点

#### 1. 多尺度检测
使用 Feature Pyramid Network (FPN) 检测不同大小的人脸：
- **大特征图**：检测小人脸（40~80px）
- **中特征图**：检测中等人脸（80~160px）
- **小特征图**：检测大人脸（160px以上）

#### 2. Anchor-Based 检测
预设多个候选框（anchors），模型预测偏移量：
```python
# 真实坐标 = anchor坐标 + 预测偏移量
real_x = anchor_x + pred_offset_x * variance
real_y = anchor_y + pred_offset_y * variance
```

#### 3. NMS 后处理
使用非极大值抑制（Non-Maximum Suppression）去除重叠框：
```python
# 伪代码
boxes = sort_by_confidence(boxes)  # 按置信度排序
for box in boxes:
    if IoU(box, kept_boxes) > 0.4:  # 重叠度阈值
        discard(box)
    else:
        keep(box)
```

### 8.2.5 性能指标（RK3568 NPU）

| 指标 | 值 |
|------|---|
| **推理时间** | ~60ms |
| **准确率** | 95%+ (WIDER FACE Easy) |
| **最小人脸** | 40×40 像素 |
| **最大角度** | ±60° |

---

## 8.3 MobileFaceNet 模型

### 8.3.1 功能定位

**MobileFaceNet** 是一个**人脸识别模型**，负责从对齐后的人脸图像中提取特征向量。

**核心功能**：
- 将人脸图像编码为 512 维特征向量
- 相同人脸的特征向量距离近，不同人脸距离远
- 特征向量可用于：
  - **1:1 验证**：判断两张照片是否为同一人
  - **1:N 识别**：在数据库中搜索匹配的人脸
  - **聚类分析**：将相册中的人脸按人分组

### 8.3.2 模型规格

| 属性 | 值 |
|------|---|
| **模型架构** | MobileNet V2 改进版 |
| **输入尺寸** | 112×112×3 (RGB) |
| **输入格式** | 浮点数组，范围 [-1, 1] |
| **输出维度** | 512 |
| **特征类型** | L2 归一化的特征向量 |
| **模型文件** | `mobilefacenet.rknn` (~4MB) |

### 8.3.3 输出格式

**特征向量**：
```c
float embedding[512];  // 512维浮点数组
```

**特性**：
- **数值范围**：每个分量约在 [-0.3, 0.3]
- **向量模长**：||v|| = 1.0（L2 归一化）
- **距离度量**：使用余弦相似度

**L2 归一化公式**：
```
normalized_v = v / ||v||

其中 ||v|| = sqrt(v[0]² + v[1]² + ... + v[511]²)
```

### 8.3.4 技术特点

#### 1. 轻量化设计
基于 MobileNet V2 的深度可分离卷积：
- **参数量**：~1M（传统 ResNet50：25M）
- **计算量**：~220M FLOPs
- **适合移动端**：NPU 加速约 40ms

#### 2. 度量学习训练
使用 ArcFace Loss 训练，使得：
- 同一人的特征向量聚集在一起
- 不同人的特征向量彼此分离

**特征空间示意**：
```
相似度空间（512维）

   PersonA ●●●         ← 同一人的多张照片聚集
            ●

                    ■■■ PersonB
                     ■

        ▲▲
       ▲  ▲ PersonC
```

#### 3. 余弦相似度计算
由于已经 L2 归一化，相似度等于内积：
```python
similarity = sum(emb1[i] * emb2[i] for i in range(512))
# 范围: [-1, 1]
```

**相似度阈值参考**：
```python
if similarity >= 0.7:   # 高置信度：同一人
elif similarity >= 0.6: # 中置信度：可能是同一人
elif similarity >= 0.4: # 低置信度：不确定
else:                   # 不同人
```

### 8.3.5 性能指标（RK3568 NPU）

| 指标 | 值 |
|------|---|
| **推理时间** | ~40ms |
| **准确率** | 99.5%+ (LFW 数据集) |
| **特征维度** | 512 |
| **归一化** | L2 norm = 1.0 |

---

## 8.4 两个模型的协同工作

### 8.4.1 数据流

```
原始图像 (任意尺寸)
    ↓
预处理：调整为 640×640
    ↓
RetinaFace 推理
    ↓
输出：人脸框 + 5关键点
    ↓
人脸对齐：仿射变换到 112×112
    ↓
MobileFaceNet 推理
    ↓
输出：512维特征向量
```

### 8.4.2 为什么需要两个模型？

| 阶段 | 模型 | 原因 |
|------|------|------|
| 检测 | RetinaFace | 图像中人脸位置、大小、角度未知，需要定位 |
| 对齐 | 胶水代码 | MobileFaceNet 要求输入正面对齐的人脸 |
| 识别 | MobileFaceNet | 提取稳定的特征用于比对 |

**不能跳过检测的原因**：
- 直接将整张图片输入 MobileFaceNet 会得到无意义的特征
- MobileFaceNet 训练时使用的是对齐后的 112×112 正面人脸

### 8.4.3 模型选型理由

#### 为什么选 RetinaFace？
- ✓ 同时输出边界框和关键点（一步到位）
- ✓ 多尺度检测，适应不同人脸大小
- ✓ 开源模型，易于部署
- ✓ RKNN 转换支持良好

#### 为什么选 MobileFaceNet？
- ✓ 轻量化，适合 NPU 推理
- ✓ 512 维特征平衡了精度和存储
- ✓ 训练数据充足（MS1M 数据集）
- ✓ 工业界验证广泛使用

---

## 8.5 模型文件管理

### 8.5.1 文件位置

```
face_detection/
└── models/
    ├── RetinaFace.rknn          # 人脸检测模型
    └── mobilefacenet.rknn       # 人脸识别模型
```

### 8.5.2 模型格式说明

**RKNN 格式**：
- Rockchip Neural Network 专用格式
- 针对 RK3568 NPU 优化
- 包含量化信息（INT8 或 FP16）
- 不可跨平台使用（仅限 Rockchip 芯片）

**转换流程**（已完成）：
```
ONNX/PyTorch 模型
    ↓ rknn-toolkit2
RKNN 模型（针对 RK3568 优化）
    ↓ 部署到板子
NPU 推理
```

---

## 8.6 模型使用注意事项

### 8.6.1 RetinaFace 使用要点

1. **输入预处理**：
   ```python
   # 必须调整为 640×640
   resized = cv2.resize(img, (640, 640))

   # 归一化到 [-1, 1]
   normalized = (resized - 127.5) / 128.0
   ```

2. **置信度阈值**：
   ```c
   #define CONF_THRESHOLD 0.5f  // 推荐 0.5
   ```
   - 过低：误检增多
   - 过高：漏检增多

3. **NMS 阈值**：
   ```c
   #define NMS_THRESHOLD 0.4f  // 推荐 0.4
   ```

### 8.6.2 MobileFaceNet 使用要点

1. **输入必须对齐**：
   ```python
   # 错误：直接使用检测框裁剪
   face_crop = img[y1:y2, x1:x2]  # ✗

   # 正确：使用关键点对齐
   aligned = align_face(img, landmarks)  # ✓
   ```

2. **输出必须归一化**：
   ```c
   // 检查向量模长
   float norm = 0.0f;
   for (int i = 0; i < 512; i++) {
       norm += embedding[i] * embedding[i];
   }
   norm = sqrt(norm);
   // norm 应该接近 1.0
   ```

3. **相似度阈值选择**：
   ```python
   # 根据应用场景调整
   THRESHOLD_STRICT = 0.7   # 安全应用（如支付）
   THRESHOLD_NORMAL = 0.6   # 通用应用（如相册）
   THRESHOLD_LOOSE = 0.5    # 宽松应用（如推荐）
   ```

---

## 8.7 总结

| 模型 | RetinaFace | MobileFaceNet |
|------|------------|---------------|
| **作用** | 人脸检测 | 人脸识别 |
| **输入** | 640×640 RGB | 112×112 RGB（对齐） |
| **输出** | 人脸框+5关键点 | 512维特征向量 |
| **推理时间** | ~60ms | ~40ms |
| **关键技术** | FPN + Anchor | MobileNet + ArcFace |
| **适用场景** | 定位人脸 | 特征提取 |

**关键要点**：
- RetinaFace 负责**定位**，MobileFaceNet 负责**识别**
- 两个模型缺一不可，协同工作
- 中间需要人脸对齐步骤
- 特征向量使用余弦相似度比对

**下一步**：参阅 `img_preprocess.md` 了解图片预处理的详细步骤。
