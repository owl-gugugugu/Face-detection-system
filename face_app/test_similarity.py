#!/usr/bin/env python3
"""
æ‰¹é‡äººè„¸ç›¸ä¼¼åº¦æµ‹è¯•è„šæœ¬
ç”¨äºæµ‹è¯•åŒä¸€äººçš„å¤šå¼ ç…§ç‰‡ä¹‹é—´çš„ç›¸ä¼¼åº¦

Usage:
    python test_similarity.py --images imgs/1.jpg imgs/2.jpg imgs/3.jpg
    æˆ–
    python test_similarity.py --dir imgs/ --pattern "*.jpg"
"""

import ctypes
import numpy as np
import argparse
import os
import sys
import time
import cv2
from pathlib import Path
from datetime import datetime
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt
import seaborn as sns

# å¯¼å…¥ test_api.py ä¸­çš„é…ç½®å’Œåº“åŠ è½½
from test_api import lib, FaceEngine, LIB_PATH, RETINAFACE_MODEL, MOBILEFACENET_MODEL

# ========================================
# é…ç½®
# ========================================
OUTPUT_DIR = "./similarity_test_output"  # è¾“å‡ºç›®å½•


def print_header(text):
    """æ‰“å°æ ‡é¢˜"""
    print(f"\n{'=' * 70}")
    print(f"  {text}")
    print('=' * 70)


def extract_all_features(engine, image_paths):
    """
    æ‰¹é‡æå–ç‰¹å¾å‘é‡

    Args:
        engine: FaceEngine å®ä¾‹
        image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨

    Returns:
        dict: {image_path: (feature, timing_stats)}
    """
    print_header("æ­¥éª¤ 1: æå–ç‰¹å¾å‘é‡")

    results = {}
    all_timings = []

    for i, image_path in enumerate(image_paths, 1):
        print(f"\n[{i}/{len(image_paths)}] Processing: {image_path}")

        feature, timing = engine.extract_feature(
            image_path,
            save_output=False  # æš‚ä¸ä¿å­˜å•å¼ ç»“æœ
        )

        if feature is not None:
            results[image_path] = (feature, timing)
            all_timings.append(sum(timing.values()) * 1000)
            print(f"  âœ“ Success")
        else:
            print(f"  âœ— Failed to extract feature")
            results[image_path] = (None, None)

    # ç»Ÿè®¡ä¿¡æ¯
    if all_timings:
        print(f"\nğŸ“Š Extraction Statistics:")
        print(f"  Success rate:  {len(all_timings)}/{len(image_paths)}")
        print(f"  Avg time:      {np.mean(all_timings):.2f} ms")
        print(f"  Min time:      {np.min(all_timings):.2f} ms")
        print(f"  Max time:      {np.max(all_timings):.2f} ms")

    return results


def compute_similarity_matrix(engine, results):
    """
    è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ

    Args:
        engine: FaceEngine å®ä¾‹
        results: extract_all_features è¿”å›çš„ç»“æœ

    Returns:
        tuple: (similarity_matrix, image_names, comparison_times)
    """
    print_header("æ­¥éª¤ 2: è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ")

    # è¿‡æ»¤å‡ºæˆåŠŸæå–ç‰¹å¾çš„å›¾ç‰‡
    valid_results = {k: v for k, v in results.items() if v[0] is not None}
    image_paths = list(valid_results.keys())
    n = len(image_paths)

    if n < 2:
        print("âœ— Error: Need at least 2 valid images for comparison")
        return None, None, None

    # åˆå§‹åŒ–ç›¸ä¼¼åº¦çŸ©é˜µ
    similarity_matrix = np.zeros((n, n))
    comparison_times = []

    print(f"\nComputing {n}x{n} similarity matrix...")

    # è®¡ç®—ä¸¤ä¸¤ç›¸ä¼¼åº¦
    for i in range(n):
        for j in range(n):
            if i == j:
                similarity_matrix[i][j] = 1.0  # è‡ªå·±å’Œè‡ªå·±ç›¸ä¼¼åº¦ä¸º1
            elif i < j:  # åªè®¡ç®—ä¸Šä¸‰è§’
                feature_i = valid_results[image_paths[i]][0]
                feature_j = valid_results[image_paths[j]][0]

                similarity, comp_time = engine.compare_faces(feature_i, feature_j)
                similarity_matrix[i][j] = similarity
                similarity_matrix[j][i] = similarity  # å¯¹ç§°çŸ©é˜µ

                comparison_times.append(comp_time)

                print(f"  {Path(image_paths[i]).name} vs {Path(image_paths[j]).name}: "
                      f"{similarity:.4f} ({comp_time:.4f} ms)")

    # æå–å›¾ç‰‡åç§°
    image_names = [Path(p).name for p in image_paths]

    print(f"\nğŸ“Š Comparison Statistics:")
    print(f"  Total comparisons: {len(comparison_times)}")
    print(f"  Avg time:          {np.mean(comparison_times):.4f} ms")

    return similarity_matrix, image_names, comparison_times


def visualize_similarity_matrix(similarity_matrix, image_names, output_dir):
    """
    å¯è§†åŒ–ç›¸ä¼¼åº¦çŸ©é˜µï¼ˆçƒ­åŠ›å›¾ï¼‰

    Args:
        similarity_matrix: nÃ—n ç›¸ä¼¼åº¦çŸ©é˜µ
        image_names: å›¾ç‰‡åç§°åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
    """
    print_header("æ­¥éª¤ 3: ç”Ÿæˆå¯è§†åŒ–ç»“æœ")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # ç»˜åˆ¶çƒ­åŠ›å›¾
    plt.figure(figsize=(10, 8))
    sns.heatmap(
        similarity_matrix,
        annot=True,  # æ˜¾ç¤ºæ•°å€¼
        fmt='.4f',  # æ ¼å¼åŒ–ä¸º4ä½å°æ•°
        cmap='RdYlGn',  # çº¢-é»„-ç»¿é…è‰²ï¼ˆä½-ä¸­-é«˜ï¼‰
        xticklabels=image_names,
        yticklabels=image_names,
        vmin=0,
        vmax=1,
        cbar_kws={'label': 'Cosine Similarity'}
    )
    plt.title('Face Similarity Matrix', fontsize=16, fontweight='bold')
    plt.xlabel('Image', fontsize=12)
    plt.ylabel('Image', fontsize=12)
    plt.tight_layout()

    # ä¿å­˜çƒ­åŠ›å›¾
    heatmap_path = Path(output_dir) / f"similarity_matrix_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
    plt.savefig(heatmap_path, dpi=150)
    plt.close()

    print(f"  âœ“ Heatmap saved: {heatmap_path}")

    return heatmap_path


def generate_report(similarity_matrix, image_names, results, comparison_times, output_dir, threshold=0.5):
    """
    ç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š

    Args:
        similarity_matrix: ç›¸ä¼¼åº¦çŸ©é˜µ
        image_names: å›¾ç‰‡åç§°åˆ—è¡¨
        results: ç‰¹å¾æå–ç»“æœ
        comparison_times: æ¯”å¯¹è€—æ—¶åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
    """
    print_header("æ­¥éª¤ 4: ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š")

    # åˆ›å»ºæŠ¥å‘Šæ–‡ä»¶
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    report_path = Path(output_dir) / f"similarity_report_{timestamp}.txt"

    with open(report_path, 'w', encoding='utf-8') as f:
        # æ ‡é¢˜
        f.write("=" * 70 + "\n")
        f.write("           Face Similarity Test Report\n")
        f.write("=" * 70 + "\n")
        f.write(f"Test Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Threshold: {threshold}\n")
        f.write("\n")

        # 1. æµ‹è¯•å›¾ç‰‡åˆ—è¡¨
        f.write("-" * 70 + "\n")
        f.write("1. Test Images\n")
        f.write("-" * 70 + "\n")
        valid_results = {k: v for k, v in results.items() if v[0] is not None}
        for i, (path, (feature, timing)) in enumerate(valid_results.items(), 1):
            f.write(f"[{i}] {path}\n")
            f.write(f"    Feature Norm: {np.linalg.norm(feature):.4f}\n")
            f.write(f"    Extraction Time: {sum(timing.values())*1000:.2f} ms\n")
        f.write("\n")

        # 2. ç›¸ä¼¼åº¦çŸ©é˜µ
        f.write("-" * 70 + "\n")
        f.write("2. Similarity Matrix\n")
        f.write("-" * 70 + "\n")
        f.write("     ")
        for name in image_names:
            f.write(f"{name:>12} ")
        f.write("\n")

        for i, name in enumerate(image_names):
            f.write(f"{name:<12} ")
            for j in range(len(image_names)):
                f.write(f"{similarity_matrix[i][j]:>12.4f} ")
            f.write("\n")
        f.write("\n")

        # 3. è¯¦ç»†å¯¹æ¯”ç»“æœ
        f.write("-" * 70 + "\n")
        f.write("3. Pairwise Comparison Details\n")
        f.write("-" * 70 + "\n")
        n = len(image_names)
        pair_index = 0
        for i in range(n):
            for j in range(i + 1, n):
                similarity = similarity_matrix[i][j]
                comp_time = comparison_times[pair_index]
                pair_index += 1

                match = "âœ“ MATCH" if similarity >= threshold else "âœ— NO MATCH"
                f.write(f"{image_names[i]} vs {image_names[j]}:\n")
                f.write(f"  Similarity: {similarity:.4f}\n")
                f.write(f"  Time:       {comp_time:.4f} ms\n")
                f.write(f"  Result:     {match}\n")
                f.write("\n")

        # 4. ç»Ÿè®¡åˆ†æ
        f.write("-" * 70 + "\n")
        f.write("4. Statistical Analysis\n")
        f.write("-" * 70 + "\n")

        # æå–éå¯¹è§’çº¿å…ƒç´ ï¼ˆå®é™…æ¯”å¯¹ç»“æœï¼‰
        n = similarity_matrix.shape[0]
        similarities = []
        for i in range(n):
            for j in range(i + 1, n):
                similarities.append(similarity_matrix[i][j])

        f.write(f"Total Comparisons: {len(similarities)}\n")
        f.write(f"Similarity Statistics:\n")
        f.write(f"  Mean:   {np.mean(similarities):.4f}\n")
        f.write(f"  Median: {np.median(similarities):.4f}\n")
        f.write(f"  Std:    {np.std(similarities):.4f}\n")
        f.write(f"  Min:    {np.min(similarities):.4f}\n")
        f.write(f"  Max:    {np.max(similarities):.4f}\n")
        f.write("\n")

        # åŸºäºé˜ˆå€¼çš„åˆ¤æ–­
        matches = sum(1 for s in similarities if s >= threshold)
        f.write(f"Threshold Analysis (threshold={threshold}):\n")
        f.write(f"  Matches:     {matches}/{len(similarities)} ({matches/len(similarities)*100:.1f}%)\n")
        f.write(f"  No Matches:  {len(similarities)-matches}/{len(similarities)} ({(len(similarities)-matches)/len(similarities)*100:.1f}%)\n")
        f.write("\n")

        # 5. æ€§èƒ½æ•°æ®
        f.write("-" * 70 + "\n")
        f.write("5. Performance Metrics\n")
        f.write("-" * 70 + "\n")

        extraction_times = [sum(v[1].values())*1000 for v in valid_results.values()]
        f.write(f"Feature Extraction:\n")
        f.write(f"  Avg Time: {np.mean(extraction_times):.2f} ms\n")
        f.write(f"  Min Time: {np.min(extraction_times):.2f} ms\n")
        f.write(f"  Max Time: {np.max(extraction_times):.2f} ms\n")
        f.write("\n")

        f.write(f"Similarity Comparison:\n")
        f.write(f"  Avg Time: {np.mean(comparison_times):.4f} ms\n")
        f.write(f"  Min Time: {np.min(comparison_times):.4f} ms\n")
        f.write(f"  Max Time: {np.max(comparison_times):.4f} ms\n")
        f.write("\n")

        # 6. ç»“è®º
        f.write("-" * 70 + "\n")
        f.write("6. Conclusions\n")
        f.write("-" * 70 + "\n")

        if len(similarities) > 0:
            avg_sim = np.mean(similarities)
            if avg_sim >= 0.7:
                f.write("âœ“ EXCELLENT: All images show very high similarity.\n")
                f.write("  This indicates they are very likely the same person.\n")
            elif avg_sim >= 0.6:
                f.write("âœ“ GOOD: Images show high similarity.\n")
                f.write("  They are likely the same person.\n")
            elif avg_sim >= 0.5:
                f.write("âš  MODERATE: Images show moderate similarity.\n")
                f.write("  May need manual review or better quality images.\n")
            else:
                f.write("âœ— LOW: Images show low similarity.\n")
                f.write("  They may not be the same person, or image quality is poor.\n")
        f.write("\n")

        f.write("=" * 70 + "\n")
        f.write("End of Report\n")
        f.write("=" * 70 + "\n")

    print(f"  âœ“ Report saved: {report_path}")

    # åŒæ—¶æ‰“å°åˆ°å±å¹•
    print(f"\nğŸ“Š Quick Summary:")
    print(f"  Images tested:     {len(image_names)}")
    print(f"  Total comparisons: {len(similarities)}")
    print(f"  Avg similarity:    {np.mean(similarities):.4f}")
    print(f"  Matches (â‰¥{threshold}):   {matches}/{len(similarities)}")

    return report_path


def save_annotated_images(results, output_dir):
    """
    ä¿å­˜å¸¦æ³¨é‡Šçš„å›¾ç‰‡

    Args:
        results: ç‰¹å¾æå–ç»“æœ
        output_dir: è¾“å‡ºç›®å½•
    """
    print_header("æ­¥éª¤ 5: ä¿å­˜å¸¦æ³¨é‡Šçš„å›¾ç‰‡")

    annotated_dir = Path(output_dir) / "annotated_images"
    annotated_dir.mkdir(parents=True, exist_ok=True)

    for image_path, (feature, timing) in results.items():
        if feature is None:
            continue

        # è¯»å–å›¾ç‰‡
        img = cv2.imread(image_path)
        if img is None:
            print(f"  âœ— Cannot read: {image_path}")
            continue

        h, w = img.shape[:2]

        # æ·»åŠ åŠé€æ˜èƒŒæ™¯
        overlay = img.copy()
        cv2.rectangle(overlay, (10, 10), (w - 10, 150), (0, 0, 0), -1)
        img = cv2.addWeighted(img, 0.7, overlay, 0.3, 0)

        # æ·»åŠ æ–‡æœ¬ä¿¡æ¯
        font = cv2.FONT_HERSHEY_SIMPLEX
        y_offset = 35

        cv2.putText(img, Path(image_path).name, (20, y_offset),
                    font, 0.7, (255, 255, 255), 2)
        y_offset += 30

        cv2.putText(img, f"Feature Dim: 512", (20, y_offset),
                    font, 0.5, (0, 255, 0), 1)
        y_offset += 25

        cv2.putText(img, f"Norm: {np.linalg.norm(feature):.4f}", (20, y_offset),
                    font, 0.5, (0, 255, 0), 1)
        y_offset += 25

        total_time = sum(timing.values())
        cv2.putText(img, f"Time: {total_time*1000:.2f} ms", (20, y_offset),
                    font, 0.5, (0, 255, 255), 1)

        # ä¿å­˜
        output_path = annotated_dir / Path(image_path).name
        cv2.imwrite(str(output_path), img)
        print(f"  âœ“ Saved: {output_path.name}")


def main():
    parser = argparse.ArgumentParser(description="Batch Face Similarity Test Script")
    parser.add_argument(
        "--images",
        type=str,
        nargs='+',
        default=None,
        help="List of image paths"
    )
    parser.add_argument(
        "--dir",
        type=str,
        default="imgs",
        help="Directory containing images (default: imgs)"
    )
    parser.add_argument(
        "--pattern",
        type=str,
        default="[1-3].jpg",
        help="Filename pattern (default: [1-3].jpg)"
    )
    parser.add_argument(
        "--threshold",
        type=float,
        default=0.5,
        help="Similarity threshold (default: 0.5)"
    )
    parser.add_argument(
        "--output",
        type=str,
        default=OUTPUT_DIR,
        help="Output directory"
    )
    parser.add_argument(
        "--retinaface",
        type=str,
        default=RETINAFACE_MODEL,
        help="RetinaFace model path"
    )
    parser.add_argument(
        "--mobilefacenet",
        type=str,
        default=MOBILEFACENET_MODEL,
        help="MobileFaceNet model path"
    )

    args = parser.parse_args()

    print_header("Face Similarity Batch Test")
    print(f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Output: {args.output}")
    print(f"Threshold: {args.threshold}")

    # è·å–å›¾ç‰‡åˆ—è¡¨
    if args.images:
        image_paths = args.images
    else:
        # ä»ç›®å½•è¯»å–
        image_dir = Path(args.dir)
        if not image_dir.exists():
            print(f"âœ— Error: Directory not found: {image_dir}")
            return

        import glob
        pattern_path = str(image_dir / args.pattern)
        image_paths = glob.glob(pattern_path)

        if not image_paths:
            print(f"âœ— Error: No images found matching pattern: {pattern_path}")
            return

    image_paths.sort()
    print(f"\nFound {len(image_paths)} images:")
    for i, path in enumerate(image_paths, 1):
        print(f"  [{i}] {path}")

    if len(image_paths) < 2:
        print("\nâœ— Error: Need at least 2 images for comparison")
        return

    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if not os.path.exists(args.retinaface):
        print(f"âœ— Error: RetinaFace model not found: {args.retinaface}")
        return
    if not os.path.exists(args.mobilefacenet):
        print(f"âœ— Error: MobileFaceNet model not found: {args.mobilefacenet}")
        return

    # åˆ›å»º FaceEngine å®ä¾‹
    try:
        engine = FaceEngine(args.retinaface, args.mobilefacenet)
    except RuntimeError as e:
        print(f"âœ— {e}")
        return

    # æ­¥éª¤ 1: æå–æ‰€æœ‰ç‰¹å¾
    results = extract_all_features(engine, image_paths)

    # æ­¥éª¤ 2: è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
    similarity_matrix, image_names, comparison_times = compute_similarity_matrix(engine, results)

    if similarity_matrix is None:
        print("\nâœ— Test failed: Not enough valid images")
        return

    # æ­¥éª¤ 3: å¯è§†åŒ–ç›¸ä¼¼åº¦çŸ©é˜µ
    heatmap_path = visualize_similarity_matrix(similarity_matrix, image_names, args.output)

    # æ­¥éª¤ 4: ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    report_path = generate_report(
        similarity_matrix,
        image_names,
        results,
        comparison_times,
        args.output,
        args.threshold
    )

    # æ­¥éª¤ 5: ä¿å­˜å¸¦æ³¨é‡Šçš„å›¾ç‰‡
    save_annotated_images(results, args.output)

    # å®Œæˆ
    print_header("Test Completed Successfully")
    print(f"\nğŸ“ Output files:")
    print(f"  - Heatmap:  {heatmap_path}")
    print(f"  - Report:   {report_path}")
    print(f"  - Annotated images: {args.output}/annotated_images/")
    print(f"\nâœ“ All done!\n")


if __name__ == "__main__":
    main()
