## 分层设计

不在 FastAPI 的路由函数里直接写 `ctypes` 代码,而是封装一层 Python 类（Wrapper），作为桥梁。

`face_detection/` 是 C++ 源码编译环境，它的产物只是一个 `.so` 文件。而 `backend/` 是 运行时环境，Python 包裹类是后端应用的一部分，负责驱动这个 `.so` 文件。

*   Layer 1 (C++ .so): 负责计算（检测+对齐+识别），只吐出 512维 数组
*   Layer 2 (Python Wrapper): 负责加载 .so，管理内存指针，提供 Python 友好的函数（输入 bytes，输出 list）
*   Layer 3 (FastAPI): 负责接收 HTTP 请求，调用 Layer 2，查询数据库进行人脸比对，返回 JSON


## 包裹类 core/face_wrapper.py

把之前 test_api.py 的代码封装成一个单例类。

core/face_wrapper.py 的工作就是翻译。它把 Python 的图片（bytes）翻译给 C++，再把 C++ 算出来的向量（float array）翻译回 Python List。所有的数据库操作、开门逻辑、权限判断，**统统不要写在这里**。

这个文件必须包含以下 5 个核心部分：（示例）
1. 动态库加载与路径管理：
  - 找到 libs/libface_engine.so、models/RetinaFace.rknn 和 models/mobilefacenet.rknn 的绝对路径
  - 使用 ctypes.CDLL 加载 .so 文件

2. C 函数的参数类型定义 (Argtypes)
  - 告诉 Python，C++ 里的函数接收什么类型的数据。最关键的一步，配错了程序直接崩溃
  - 具体定义内容：
    - init_engine: 接收两个字符串指针 (c_char_p)，返回一个通用指针 (c_void_p)
    - extract_feature: 接收一个引擎指针 (c_void_p)、一个图片字节数组指针 (POINTER(c_ubyte))、一个整数长度 (c_int)、一个输出数组指针 (POINTER(c_float))
    - release_engine: 接收一个引擎指针 (c_void_p)

3. 初始化方法 (__init__)

   - 封装引擎启动过程
   - 逻辑：
     - 接收模型路径
     - 将 Python 字符串路径编码为字节串（UTF-8）
     - 调用 C++ 的 init_engine 接口
     - **保存** C++ 返回的 engine_ptr（引擎指针），这个指针是后续所有操作的身份证，必须一直持有

4. 核心功能方法 (extract_feature)

   - fastAPI和人脸识别模块的**唯一**交互点：发送图片，接收向量数组

   - 输入：Python 的 bytes (图片文件流)

   - 输出：Python 的 List[float] (512维向量) 或 None

   - 内部逻辑：

     1. 内存拷贝：把 Python 的 bytes 图片数据，复制到一个 ctypes 创建的 C 语言字节数组中

     2. 预分配内存：创建一个长度为 512 的 C 语言浮点数数组，用来接收 C++ 填回来的结果

     3. 调用 C++：把 引擎指针、图片数组、图片长度、结果数组 传给 C++ 函数

     4. 结果转换：

        如果 C++ 返回 0（成功）：把结果数组转为 Python List 返回

        如果 C++ 返回 -2（无人脸）：返回 None

5. 资源释放方法 (__del__)

   - 任务：防止内存泄漏
   - 逻辑：当 Python 对象被销毁时，自动调用 C++ 的 release_engine，把之前申请的 NPU 上下文和内存释放掉

## fastAPI 接口

后端主要需要两个接口：

- 录入人脸 (api/face/capture)：POST方法，提取特征 -> 存入数据库：
  
  截取当前摄像头的一帧 -> 转 bytes -> 调引擎 -> 存库
  - Step 1: 从摄像头获取一张图片
  - Step 2: 调用 face_wrapper.extract(图片) 得到向量 A
  - Step 3 (业务): 将 {"name": "张三", "vector": A} **存入数据库**
- 人脸识别 (api/face/recognize)：POST方法，提取特征 -> 计算相似度 -> 返回是谁：
  
  **只用于测试，因为实际上是开发板使用后台线程自动检测和比对人脸**
  接收上传的图片 bytes -> 调引擎 -> 查库 -> 返回结果
  - Step 1: 从摄像头获取一张图片
  - Step 2: 调用 face_wrapper.extract(图片) 得到向量 B
  - Step 3 (业务): 从数据库取出所有人的向量，计算 B 与它们的**相似度**，找出最大值

## 数据流

当前端（手机网页或开发板本地 UI）发起一次识别请求时：

1.  Request: `POST /api/recognize` (Multipart/form-data 包含图片 `file`)
2.  FastAPI: `await file.read()` 拿到二进制数据 (`bytes`)
3.  Wrapper: `ctypes` 将 `bytes` 内存首地址传给 `.so`
4.  C++ Engine:
    *   `cv::imdecode` (内存解码)
    *   `RetinaFace` (检测)
    *   `WarpAffine` (对齐)
    *   `MobileFaceNet` (识别)
    *   Return: 写满 512 个 float 的数组
5.  FastAPI: 拿到 Python List `[0.123, -0.456, ...]`
6.  Business Logic: 遍历 SQL 数据库，用 `numpy` 算余弦相似度
7.  Response: JSON `{ "code": 200, "user": "admin" }`

